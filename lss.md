# LSS

## 一、Lift（提升图像特征到3D）

### 输入：

- 多个相机图像：{Xk ∈ ℝ³×H×W}
- 每个图像的外参矩阵 Ek 和内参矩阵 Ik

### 步骤：

1. **为每个图像独立处理**：
   - 使用 CNN（如 EfficientNet）提取每个像素的上下文特征向量 c ∈ ℝᶜ；
   - 同时预测该像素的深度概率分布 α ∈ ℝᴰ（D 为离散深度层数）。
2. **构建“体素特征体”**：
   - 每个像素被“提升”为一条射线，对应 D 个深度层；
   - 每一层上的特征向量为 `c_d = α_d * c` (深度概率分布 * 特征向量)；
   - 最终形成一个**frustum-shaped point cloud**（棱台形点云），表示该像素在不同深度上的潜在表示。

------

## 二、Splat（投影到鸟瞰图）

### 步骤：

1. **从图像空间投影到 BEV 坐标系**：
   - 利用相机的外参和内参将棱台形点云坐标映射到 BEV 平面上。
2. **将点云投影为 BEV 特征图**：
   - 使用 Pillar Pooling（柱状池化）将点云特征进行聚合，形成固定尺寸的 BEV 表示张量 `y ∈ ℝᶜ×X×Y`；
   - 每个 BEV cell 聚合落入其中的点云特征之和。
3. **使用 BEV CNN 进一步处理**：
   - 使用 ResNet 结构处理 BEV 特征图，输出语义分割图（如车道、可通行区域、车辆等）。

------

## 三、Shoot（运动规划）

### 目标：

基于 BEV 语义图，预测最优的行驶轨迹，执行端到端运动规划。

### 步骤：

1. **准备轨迹模板**：

   - 通过 K-Means 对大量专家驾驶轨迹聚类，得出 K 个模板轨迹 `{τ₁, τ₂, ..., τ_K}`。

2. **评分机制**：

   - 计算每个轨迹 τᵢ 在 BEV 成本图中的代价：

     p(τi∣o)=exp⁡(−∑(x,y)∈τico(x,y))∑τ∈Texp⁡(−∑(x,y)∈τco(x,y))p(τ_i | o) = \frac{\exp(-\sum_{(x,y) ∈ τ_i} c_o(x,y))}{\sum_{\tau ∈ T} \exp(-\sum_{(x,y) ∈ τ} c_o(x,y))}p(τi∣o)=∑τ∈Texp(−∑(x,y)∈τco(x,y))exp(−∑(x,y)∈τico(x,y))

   - 将规划任务转化为一个 K 类分类问题（选择最佳轨迹模板）。

3. **训练方式**：

   - 使用交叉熵损失，最小化专家轨迹与模板轨迹之间的距离；
   - 可实现端到端训练，使感知模块与规划模块联合优化。

------

## 四、模型特性与优势

- **端到端可微**：从图像到 BEV 表示、再到轨迹预测均可反向传播；
- **无需激光雷达**：完全基于 RGB 图像学习语义和几何；
- **鲁棒性强**：支持摄像头缺失和外参扰动的鲁棒训练；
- **可零样本泛化到新摄像头布局**（zero-shot camera rig transfer）。
