## Diffusion 的核心思想

扩散模型包含两个过程：

### 1. **正向扩散过程：**将原图不断加噪变为高斯噪声的过程。

将原始数据（如图像）逐步加入高斯噪声，最终变成标准高斯噪声。
$$
q(x_t | x_{t-1}) = \mathcal{N}(x_t; \sqrt{1 - \beta_t}x_{t-1}, \beta_t I)
$$

#### xt为高斯分布的样本

#### βt 本身 **不是随机的**，而是一个**预设好的常量序列**

在扩散模型中：

- β1,β2,...,βT 是事先定义好的一组常数（长度为时间步数 T）
- 它们表示每一步的噪声强度
- 通常是线性、余弦、指数等 **调度（schedule）策略**



---



### 2. **反向生成过程：一步将xt->x0还原**

训练一个神经网络（通常是UNet）来逐步“去噪”，从随机噪声中恢复原始数据：
$$
p_\theta(x_{t-1} | x_t) = \mathcal{N}(x_{t-1}; \mu_\theta(x_t, t), \Sigma_\theta(x_t, t))
$$


也就是说，Diffusion 就是训练一个模型，**从噪声生成清晰图像/轨迹/语音**。

反向不像正向需要很多步，只要一步就还原为x0。正向生成的每一步都能作为数据集训练。



## 📥 二、输入输出

### ✅ 输入：

- 一个**高斯噪声向量** xTx_TxT（或经过多步加噪后的中间变量 xtx_txt）
- 条件输入（可选）：如文本提示、边缘图、语义标签、目标位置等
- 时间步 t：表示当前“去噪”的第几步

### ✅ 输出：

- 网络预测的 **噪声** ϵ^θ(xt,t)\hat{\epsilon}_\theta(x_t, t)ϵ^θ(xt,t)，或恢复图像 x^t−1\hat{x}_{t-1}x^t−1
- 经过多步去噪后，最终输出数据 x^0\hat{x}_0x^0（图像/轨迹/音频等）



## 🧱 三、常用网络结构：**UNet**

扩散模型最常用的网络结构是 **UNet**，它是一种编码器-解码器结构，中间加入了跳跃连接。

### 构成模块：

- **Downsampling Path**：逐步缩小图像，提取高级特征（Conv + GroupNorm + ResBlock）
- **Bottleneck**：最低分辨率，抽象表示（带时间或文本条件）
- **Upsampling Path**：逐步恢复图像大小，结合 skip-connection
- **Time Embedding**：把时间步 t 嵌入成向量，加入每一层，用于“定位”当前去噪阶段
