# DETR

![Screenshot from 2025-05-14 09-01-57](https://github.com/user-attachments/assets/9a2ae0ee-873d-4450-a805-9bc98c82da8a)

DETRï¼ˆDEtection TRansformerï¼‰æ˜¯ Facebook æå‡ºçš„ä¸€ç§ç›®æ ‡æ£€æµ‹æ–¹æ³•ï¼Œå®ƒå°†ç›®æ ‡æ£€æµ‹ä»»åŠ¡è½¬åŒ–ä¸ºä¸€ä¸ªé›†åˆé¢„æµ‹ï¼ˆset predictionï¼‰é—®é¢˜ï¼Œç”¨ä¸€ç§ç«¯åˆ°ç«¯çš„æ–¹å¼æ¥è§£å†³ï¼Œä¸ä¾èµ–äºä¼ ç»Ÿçš„æ£€æµ‹å™¨ç»“æ„ï¼ˆæ¯”å¦‚ anchorã€NMS ç­‰ï¼‰ã€‚

---

## ä¸»è¦åˆ›æ–°ç‚¹
**ç«¯åˆ°ç«¯çš„ç›®æ ‡æ£€æµ‹ï¼š**

DETR æŠ›å¼ƒäº†ä¼ ç»Ÿæ£€æµ‹å™¨ä¸­å¸¸è§çš„æ‰‹å·¥è®¾è®¡ç»„ä»¶ï¼ˆä¾‹å¦‚é”šæ¡†ç”Ÿæˆã€å€™é€‰æ¡†æè®®ã€éæå¤§å€¼æŠ‘åˆ¶ç­‰ï¼‰ï¼Œè€Œæ˜¯é€šè¿‡ä¸€ä¸ªç»Ÿä¸€çš„ç¥ç»ç½‘ç»œç»“æ„ï¼Œç›´æ¥è¾“å‡ºæ‰€æœ‰ç‰©ä½“çš„è¾¹ç•Œæ¡†å’Œç±»åˆ«ã€‚

**ä½¿ç”¨ Transformer æ¶æ„ï¼š**

DETR åœ¨ CNN ç‰¹å¾æå–å™¨ï¼ˆå¦‚ ResNetï¼‰åæ¥å…¥ä¸€ä¸ªæ ‡å‡†çš„ Transformer ç¼–ç å™¨-è§£ç å™¨æ¶æ„ï¼Œåˆ©ç”¨å…¶å¼ºå¤§çš„å…¨å±€å»ºæ¨¡èƒ½åŠ›æ¥ç†è§£å›¾åƒä¸­çš„ç‰©ä½“åŠå…¶å…³ç³»ã€‚

**é›†åˆåŒ¹é…æŸå¤±å‡½æ•°ï¼š**

é‡‡ç”¨äº†ä¸€ä¸ªåŸºäºåŒˆç‰™åˆ©ç®—æ³•çš„é›†åˆåŒ¹é…æŸå¤±å‡½æ•°ï¼ˆHungarian Lossï¼‰ï¼Œå¯¹é¢„æµ‹çš„è¾¹ç•Œæ¡†ä¸çœŸå®æ¡†è¿›è¡Œä¸€ä¸€åŒ¹é…ï¼Œé¿å…äº†é‡å¤é¢„æµ‹ã€‚



---

## å·¥ä½œåŸç†æ¦‚è¿°

è¾“å…¥å›¾åƒé€šè¿‡ CNN æå–ç‰¹å¾ï¼›

Transformer ç¼–ç å™¨å»ºæ¨¡å›¾åƒä¸­æ‰€æœ‰åŒºåŸŸçš„å…¨å±€å…³ç³»ï¼›

è§£ç å™¨ä½¿ç”¨ä¸€ç»„å¯å­¦ä¹ çš„â€œobject queriesâ€æ¥å¹¶è¡Œåœ°é¢„æµ‹ç‰©ä½“ï¼ˆæ¯ä¸ª query å¯¹åº”ä¸€ä¸ªæ£€æµ‹ç»“æœï¼‰ï¼›

æœ€ç»ˆè¾“å‡ºä¸€ç»„å›ºå®šæ•°é‡çš„é¢„æµ‹ï¼ˆå…¶ä¸­éƒ¨åˆ†ä¸ºâ€œno objectâ€ç±»åˆ«ï¼‰ï¼Œç›´æ¥ç”Ÿæˆæ‰€æœ‰æ£€æµ‹ç»“æœã€‚

---

## ä¼˜ç‚¹

ç®€æ´ç»Ÿä¸€ï¼šDETR ä¸éœ€è¦é¢å¤–è®¾è®¡çš„å€™é€‰åŒºåŸŸã€anchorã€NMS åå¤„ç†ï¼Œæ•´ä½“ç»“æ„éå¸¸ç®€æ´ã€‚

å…¨å±€å»ºæ¨¡èƒ½åŠ›å¼ºï¼šTransformer çš„è‡ªæ³¨æ„åŠ›æœºåˆ¶èƒ½æ•æ‰å›¾åƒä¸­å„åŒºåŸŸé—´çš„å¤æ‚å…³ç³»ï¼Œå°¤å…¶å¯¹å¤§å‹ç‰©ä½“æ£€æµ‹è¡¨ç°æ›´å¥½ã€‚

å¯æ‰©å±•æ€§å¼ºï¼šä»…éœ€åŠ ä¸€ä¸ª mask åˆ†æ”¯ï¼ŒDETR å°±å¯ä»¥è½»æ¾æ‰©å±•åˆ°å…¨æ™¯åˆ†å‰²ä»»åŠ¡ã€‚

---

## ç¼ºç‚¹å’ŒæŒ‘æˆ˜

è®­ç»ƒæ”¶æ•›æ…¢ï¼šç›¸æ¯”ä¼ ç»Ÿæ–¹æ³•(resnet)éœ€è¦æ›´é•¿æ—¶é—´çš„è®­ç»ƒ(10x epoch)æ‰èƒ½è¾¾åˆ°è¾ƒå¥½æ€§èƒ½ï¼ˆæ”¶æ•›ï¼‰ï¼›

å¯¹å°ç‰©ä½“æ£€æµ‹æ•ˆæœè¾ƒå·®ï¼šç”±äºå…¶ç‰¹å¾æå–ç²’åº¦è¾ƒç²—ï¼ŒTransformer åœ¨å»ºæ¨¡å°ç›®æ ‡æ—¶ä¸å¤Ÿç²¾å‡†ï¼›

å›ºå®šæ•°é‡çš„é¢„æµ‹æ§½ï¼šå…¶è¾“å‡ºæ˜¯å›ºå®šæ•°é‡çš„ object queriesï¼Œä¸é€‚åˆæ£€æµ‹æ•°é‡æå…¶å¤šçš„åœºæ™¯ã€‚

---

## ğŸ”¹ è¾“å…¥

- å°ºå¯¸ä¸º `3 Ã— Hâ‚€ Ã— Wâ‚€` çš„å½©è‰²å›¾åƒã€‚
- æ¨¡å‹å›ºå®šç”Ÿæˆ `N` ä¸ªé¢„æµ‹ç»“æœï¼ˆä¾‹å¦‚ `N = 100`ï¼‰ï¼Œå…¶ä¸­ä¸€éƒ¨åˆ†ä¼šå¯¹åº”çœŸå®ç›®æ ‡ï¼Œå…¶ä½™è¢«æ ‡è®°ä¸ºâ€œæ— ç›®æ ‡â€ã€‚

---

## ğŸ”¹ æ¨¡å‹ç»“æ„

#### 1. CNN Backboneï¼ˆç‰¹å¾æå–ï¼‰

- é€šå¸¸ä½¿ç”¨ **ResNet-50** æˆ– **ResNet-101**ã€‚
- è¾“å‡ºä¸ºä¸€ä¸ªä½åˆ†è¾¨ç‡çš„äºŒç»´ç‰¹å¾å›¾ `f âˆˆ â„^{C Ã— H Ã— W}`ï¼Œ `C = 2048`ï¼ˆResNet æœ€åä¸€å±‚çš„è¾“å‡ºé€šé“æ•°ï¼‰ï¼Œ`H` å’Œ `W` æ˜¯åŸå›¾çš„ `1/32`ã€‚
- ä½¿ç”¨ä¸€ä¸ª `1 Ã— 1` å·ç§¯å°†é€šé“æ•°é™ä¸º `d`ï¼ˆä¾‹å¦‚ `d = 256`ï¼‰ï¼Œå¾—åˆ° `zâ‚€ âˆˆ â„^{d Ã— H Ã— W}`ã€‚

#### 2. Transformer Encoder

- è¾“å…¥æ˜¯å°† `zâ‚€` å±•å¹³åçš„åºåˆ—ï¼ˆç»´åº¦ä¸º `d Ã— HW`ï¼‰ï¼ŒåŠ ä¸Š**å›ºå®šçš„ç©ºé—´ä½ç½®ç¼–ç **ã€‚
- ç¼–ç å™¨ä¸ºæ ‡å‡† Transformer ç»“æ„ï¼ˆåŒ…å«å¤šå¤´è‡ªæ³¨æ„åŠ›ã€å‰é¦ˆç½‘ç»œã€æ®‹å·®è¿æ¥å’Œ LayerNormï¼‰ã€‚
- è¾“å‡ºæ˜¯ç¼–ç åçš„**å…¨å›¾ä¸Šä¸‹æ–‡ç‰¹å¾åºåˆ—**ã€‚

#### 3. Transformer Decoder

- è¾“å…¥æ˜¯ `N` ä¸ª**å¯å­¦ä¹ çš„ object queriesï¼ˆç›®æ ‡æŸ¥è¯¢å‘é‡ï¼‰**ï¼Œæ¯ä¸ªå‘é‡é•¿åº¦ä¸º `d`ã€‚ï¼ˆç»´åº¦ä¸º `N Ã— d`ï¼‰
- Decoder æ¯ä¸€å±‚æ‰§è¡Œï¼š
  - **è‡ªæ³¨æ„åŠ›**ï¼šå­¦ä¹ æŸ¥è¯¢ä¹‹é—´çš„ç›¸äº’å…³ç³»ã€‚
  - **äº¤å‰æ³¨æ„åŠ›**ï¼šæŸ¥è¯¢ä¸ Encoder è¾“å‡ºè¿›è¡Œäº¤äº’ï¼Œè·å–å›¾åƒä¸Šä¸‹æ–‡ã€‚
- è¾“å‡ºæ˜¯ `N Ã— d` çš„åµŒå…¥å‘é‡ï¼Œæ¯ä¸ªè¡¨ç¤ºä¸€ä¸ªç›®æ ‡å€™é€‰ã€‚

#### 4. é¢„æµ‹å¤´ï¼ˆFFNï¼‰

- æ¯ä¸ª Decoder è¾“å‡ºå‘é‡é€å…¥ä¸¤ä¸ªå°çš„å…±äº«çš„ 3 å±‚å‰é¦ˆç¥ç»ç½‘ç»œï¼ˆFFNï¼‰ï¼Œè¾“å‡ºä¸¤ä¸ªå†…å®¹ï¼š
  - ä¸€ä¸ªç±»åˆ«ï¼ˆåŒ…æ‹¬â€œæ— ç›®æ ‡â€ç±»åˆ« âˆ…ï¼‰
  - ä¸€ä¸ªè¾¹ç•Œæ¡†ï¼ˆ`cx, cy, w, h`ï¼Œå½’ä¸€åŒ–åæ ‡ï¼‰

---

### ğŸ”¹ è¾“å‡º

- `N` ä¸ªç±»åˆ«æ¦‚ç‡ï¼ˆä½¿ç”¨ Softmax åˆ†ç±»ï¼‰
- `N` ä¸ªå½’ä¸€åŒ–è¾¹ç•Œæ¡†
  
- åç»­ä½¿ç”¨ **åŒˆç‰™åˆ©ç®—æ³•**å°†é¢„æµ‹ä¸ Ground Truth è¿›è¡Œä¸€ä¸€åŒ¹é…ï¼Œè®¡ç®—æ€»æŸå¤±ï¼ˆåˆ†ç±»æŸå¤± + æ¡†æŸå¤±ï¼‰ã€‚


---

### æ•´ä½“æµç¨‹æ€»ç»“

```
images (NestedTensor)
   â†“
CNN Backboneï¼ˆå¦‚ ResNetï¼‰ â features[-1], pos[-1]
   â†“
1x1 conv input_proj + flatten
   â†“
Transformer Encoder-Decoderï¼ˆå« learnable object queriesï¼‰
   â†“
Decoder outputs hs â class_embed + bbox_embed
   â†“
åˆ†ç±»ç»“æœ pred_logits + è¾¹æ¡† pred_boxesï¼ˆå½’ä¸€åŒ–ï¼‰
```
---

## åŒˆç‰™åˆ©åŒ¹é…

### ğŸ§© åœºæ™¯è®¾å®š

æˆ‘ä»¬è®¾å®šå¦‚ä¸‹ï¼š

- **æ¨¡å‹é¢„æµ‹çš„ç›®æ ‡æ•°ï¼ˆqueriesï¼‰ = 3**
- **å›¾åƒä¸­çœŸå®ç›®æ ‡æ•°ï¼ˆGTï¼‰ = 2**

---

### æ¨¡å‹é¢„æµ‹è¾“å‡ºå¦‚ä¸‹ï¼š

| é¢„æµ‹ç´¢å¼• | ç±»åˆ«æ¦‚ç‡ï¼ˆsoftmaxåï¼‰       | è¾¹ç•Œæ¡† `(cx, cy, w, h)`      |
|----------|------------------------------|-------------------------------|
| P0       | `[0.1, 0.8, 0.1]`            | `(0.5, 0.5, 0.4, 0.3)`        |
| P1       | `[0.7, 0.2, 0.1]`            | `(0.1, 0.1, 0.2, 0.2)`        |
| P2       | `[0.3, 0.3, 0.4]`            | `(0.9, 0.9, 0.1, 0.1)`        |

> å‡è®¾ç±»åˆ«é¡ºåºä¸º `[A, B, C]`ï¼Œå…± 3 ç±»

---

### ğŸ·ï¸ Ground Truthï¼ˆGTï¼‰æ ‡æ³¨å¦‚ä¸‹ï¼š

| GTç´¢å¼• | ç±»åˆ« | è¾¹ç•Œæ¡† `(cx, cy, w, h)`       |
|--------|------|-------------------------------|
| G0     | B    | `(0.52, 0.52, 0.38, 0.28)`     |
| G1     | A    | `(0.15, 0.15, 0.25, 0.25)`     |

---

#### âœ… Step 1: æ‰¾å‡ºæ‰€æœ‰GTçš„ç±»åˆ«ï¼Œè®¡ç®— åˆ†ç±»ä»£ä»· cost_class  `cost_class = 1 - p(GTç±»)`

| é¢„æµ‹\GT | G0 (Bç±»)       | G1 (Aç±»)       |
|---------|----------------|----------------|
| P0      | `1 - 0.8 = 0.2`| `1 - 0.1 = 0.9`|
| P1      | `1 - 0.2 = 0.8`| `1 - 0.7 = 0.3`|
| P2      | `1 - 0.3 = 0.7`| `1 - 0.3 = 0.7`|

```
cost_class = -out_prob[:, tgt_ids]
```

---

#### âœ… Step 2: è¾¹ç•Œæ¡† L1 è·ç¦»ä»£ä»·cost_boxï¼ˆç²—ç•¥ä¼°ç®—ï¼‰ä¸ç®¡classï¼Œå°±æ‰¾æœ€è¿‘çš„bbox

| é¢„æµ‹\GT | G0         | G1         |
|---------|------------|------------|
| P0      | â‰ˆ `0.06`   | â‰ˆ `1.1`    |
| P1      | â‰ˆ `0.9`    | â‰ˆ `0.1`    |
| P2      | â‰ˆ `1.4`    | â‰ˆ `1.5`    |

```
out_bbox = outputs["pred_boxes"].flatten(0, 1)  # [batch_size Ã— num_queries, 4]
tgt_bbox = torch.cat([v["boxes"] for v in targets])  # æ‰€æœ‰ GT æ¡†
cost_bbox = torch.cdist(out_bbox, tgt_bbox, p=1)
```

---

#### âœ… Step 3: GIoU ä»£ä»·ï¼ˆè´Ÿ GIoUï¼‰

| é¢„æµ‹\GT | G0       | G1       |
|---------|----------|----------|
| P0      | `-0.8`   | `-0.1`   |
| P1      | `-0.1`   | `-0.9`   |
| P2      | `-0.2`   | `-0.2`   |


```
cost_giou = -generalized_box_iou(
    box_cxcywh_to_xyxy(out_bbox), 
    box_cxcywh_to_xyxy(tgt_bbox)
)
```

---

#### âœ… Step 4: æ€»åŒ¹é…ä»£ä»·ï¼ˆåŠ æƒæ±‚å’Œï¼Œæƒé‡å…¨ä¸º 1ï¼‰   

$$
C(i,j)=Î»clsâ€‹åˆ†ç±»ä»£ä»·(i,j)+Î»L1â€‹L1ä»£ä»·(i,j)+Î»IoUâ€‹GIoUä»£ä»·(i,j)
$$

| é¢„æµ‹\GT | G0                    | G1                    |
|---------|-----------------------|-----------------------|
| P0      | `0.2 + 0.06 + 0.8 = 1.06` | `0.9 + 1.1 + 0.1 = 2.1`  |
| P1      | `0.8 + 0.9 + 0.1 = 1.8`   | `0.3 + 0.1 + 0.9 = 1.3`  |
| P2      | `0.7 + 1.4 + 0.2 = 2.3`   | `0.7 + 1.5 + 0.2 = 2.4`  |

```
C = self.cost_bbox * cost_bbox + self.cost_class * cost_class + self.cost_giou * cost_giou
```
---

#### âœ… Step 5: åŒˆç‰™åˆ©åŒ¹é…ç»“æœï¼ˆæœ€å°ä»£ä»·åˆ†é…ï¼‰
åœ¨ä¸€ä¸ª äºŒç»´ä»£ä»·çŸ©é˜µC ä¸­ï¼Œé€‰å‡º ä¸€ä¸€å¯¹åº”çš„åŒ¹é…ï¼ˆæ¯è¡Œæœ€å¤šé€‰ä¸€ä¸ªåˆ—ï¼Œæ¯åˆ—æœ€å¤šé€‰ä¸€ä¸ªè¡Œï¼‰ï¼Œä½¿å¾— æ€»ä»£ä»·ä¹‹å’Œæœ€å°ã€‚ã€queryä¸ªæ•° * classæ•°ã€‘

ä¾‹å¦‚ä¸‹è¡¨ä¸­ï¼Œæ ¼å­ä¸­ä¸ºåˆ†ç±»è¯¯å·® + L1 + GIoU

|         | gt[0]=person1 | gt[1]=person2 | gt[2]=dog |
| ------- | ------------- | ------------- | --------- |
| pred[0] | **0.1**       | 1.5           | 2.0       |
| pred[1] | 2.0           | 1.7           | **0.2**   |
| pred[2] | 1.4           | **0.3**       | 1.8       |
| pred[3] | 1.2           | 1.1           | 2.5       |
| pred[4] | 2.0           | 2.2           | 2.1       |




### è¾“å‡º
åºå›ºå®šå°±æ„å‘³ç€æ¨¡å‹å‡è®¾â€œGT1 æ°¸è¿œæ˜¯æŸä¸ªä½ç½®/ç±»åˆ«çš„ç‰©ä½“â€ï¼Œè¿™å¯¹çœŸå®æ•°æ®ä¸æˆç«‹ï¼ˆç›®æ ‡çš„é¡ºåºä¼šå˜ã€ç›®æ ‡æ•°ä¼šå˜ã€ç±»åˆ«ä¼šå˜ï¼‰ã€‚

å¦‚æœå¼ºè¡Œæ’åºï¼Œåè€Œå¯èƒ½å¯¼è‡´æ¨¡å‹è¿‡æ‹Ÿåˆåˆ°æ’åºè§„åˆ™ï¼Œè€Œä¸æ˜¯å­¦ä¼šæ³›åŒ–åœ°æ£€æµ‹ç›®æ ‡ã€‚row_ind = [0, 1, 2]
col_ind = [1, 0, 2]

## Step 1ï¼šFlatten BEV ç‰¹å¾å›¾ + è‡ªæ³¨æ„åŠ›å»ºæ¨¡
```
import torch
import torch.nn as nn

# å‡è®¾è¾“å…¥çš„ BEV ç‰¹å¾å›¾
C, H, W = 256, 200, 200
bev_feature = torch.randn(C, H, W)  # [C, H, W]

# è½¬ä¸º [H*W, C]ï¼Œä¾› transformer encoder ä½¿ç”¨
bev_feature_flat = bev_feature.permute(1, 2, 0).reshape(-1, C)  # [H*W, C]

# åŠ ä¸Š batch dim: [1, H*W, C]
bev_feature_seq = bev_feature_flat.unsqueeze(0)

# å®šä¹‰ Transformer Encoder
transformer_encoder = nn.TransformerEncoder(
    encoder_layer=nn.TransformerEncoderLayer(
        d_model=C,
        nhead=8,
        dim_feedforward=512,
        dropout=0.1,
        batch_first=True
    ),
    num_layers=6
)

# è¾“å‡º Encoder åçš„å…¨å±€å»ºæ¨¡ç‰¹å¾ï¼š[1, H*W, C]
encoder_output = transformer_encoder(bev_feature_seq)
```

## âœ… Step 2ï¼šç”¨ DETR çš„ Object Queries åš Cross Attention

```
# Learnable object queriesï¼š[N_query, C]
N_query = 100
object_queries = nn.Parameter(torch.randn(N_query, C))  # éœ€è¦æ³¨å†Œåˆ°æ¨¡å‹ä¸­æ‰èƒ½è®­ç»ƒ

# åŠ ä¸Š batch dim: [1, N_query, C]
object_queries = object_queries.unsqueeze(0)

# å®šä¹‰ Transformer Decoder
transformer_decoder = nn.TransformerDecoder(
    decoder_layer=nn.TransformerDecoderLayer(
        d_model=C,
        nhead=8,
        dim_feedforward=512,
        dropout=0.1,
        batch_first=True
    ),
    num_layers=6
)

# Decoderï¼šCross Attention(Q=query, K=V=encoder_output)
decoder_output = transformer_decoder(object_queries, encoder_output)
# shape: [1, N_query, C]
â€µâ€µâ€µ
## âœ… è¾“å‡ºåˆ†ç±»å’Œè¾¹ç•Œæ¡†å›å½’ï¼ˆDETR-styleï¼‰

â€µâ€µâ€µ
# åˆ†ç±»å¤´
class_head = nn.Linear(C, 10)  # 10ç±»ç›®æ ‡

# è¾¹ç•Œæ¡†å›å½’å¤´ï¼ˆè¿™é‡Œå‡è®¾è¾“å‡º [cx, cy, w, h]ï¼‰
bbox_head = nn.Linear(C, 4)

# è¾“å‡º
class_logits = class_head(decoder_output)  # [1, 100, 10]
bboxes = bbox_head(decoder_output).sigmoid()  # [1, 100, 4] (å½’ä¸€åŒ–åæ ‡)
```
