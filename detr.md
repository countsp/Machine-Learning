# DETR

![Screenshot from 2025-05-14 09-01-57](https://github.com/user-attachments/assets/9a2ae0ee-873d-4450-a805-9bc98c82da8a)

DETR（DEtection TRansformer）是 Facebook 提出的一种目标检测方法，它将目标检测任务转化为一个集合预测（set prediction）问题，用一种端到端的方式来解决，不依赖于传统的检测器结构（比如 anchor、NMS 等）。

## 主要创新点
**端到端的目标检测：**

DETR 抛弃了传统检测器中常见的手工设计组件（例如锚框生成、候选框提议、非极大值抑制等），而是通过一个统一的神经网络结构，直接输出所有物体的边界框和类别。

**使用 Transformer 架构：**

DETR 在 CNN 特征提取器（如 ResNet）后接入一个标准的 Transformer 编码器-解码器架构，利用其强大的全局建模能力来理解图像中的物体及其关系。

**集合匹配损失函数：**

采用了一个基于匈牙利算法的集合匹配损失函数（Hungarian Loss），对预测的边界框与真实框进行一一匹配，避免了重复预测。

## 工作原理概述

输入图像通过 CNN 提取特征；

Transformer 编码器建模图像中所有区域的全局关系；

解码器使用一组可学习的“object queries”来并行地预测物体（每个 query 对应一个检测结果）；

最终输出一组固定数量的预测（其中部分为“no object”类别），直接生成所有检测结果。

## 优点

简洁统一：DETR 不需要额外设计的候选区域、anchor、NMS 后处理，整体结构非常简洁。

全局建模能力强：Transformer 的自注意力机制能捕捉图像中各区域间的复杂关系，尤其对大型物体检测表现更好。

可扩展性强：仅需加一个 mask 分支，DETR 就可以轻松扩展到全景分割任务。

## 缺点和挑战

训练收敛慢：相比传统方法(resnet)需要更长时间的训练(10x epoch)才能达到较好性能（收敛）；

对小物体检测效果较差：由于其特征提取粒度较粗，Transformer 在建模小目标时不够精准；

固定数量的预测槽：其输出是固定数量的 object queries，不适合检测数量极其多的场景。
