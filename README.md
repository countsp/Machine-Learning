# 逻辑回归（Logistic Regression）

是一种广泛用于二分类问题的统计方法。

与线性回归不同，逻辑回归的输出是一个概率值，表示样本属于某个类别的概率。

其核心思想是通过一个 Sigmoid 函数 将线性回归的结果映射到 [0, 1] 之间，以此实现分类任务。

# 梯度下降

梯度下降法（Gradient Descent）是一种常用于优化机器学习模型参数的算法，主要用于最小化损失函数。其核心思想是通过迭代更新参数，使损失函数逐渐减小，直到达到局部最小值（对于凸函数则是全局最小值）。
原理。

![Screenshot from 2024-09-23 09-27-42](https://github.com/user-attachments/assets/5c1695c2-69e0-47e1-86c7-c749c27fb5b4)

梯度下降的基本更新公式为：

$' θ=θ−α⋅∇J(θ) '$

其中：

θ 表示参数向量（例如权重）。
α 表示学习率，控制每次迭代参数更新的步长。
∇J(θ) 表示损失函数 J(θ) 对参数 θ 的梯度
