# Deformable DETR


![deformable-detr](https://github.com/fundamentalvision/Deformable-DETR/raw/main/figs/illustration.png)

**SenseTimeä¸ä¸­ç§‘å¤§ã€é¦™æ¸¯ä¸­æ–‡å¤§å­¦çš„ç ”ç©¶äººå‘˜åˆä½œå‘è¡¨åœ¨ICLR 2021ä¸Šçš„è®ºæ–‡ï¼Œæå‡ºäº†ä¸€ç§æ”¹è¿›ç‰ˆçš„DETRâ€”â€”Deformable DETRã€‚è¯¥æ–¹æ³•ä¿ç•™äº†DETRâ€œç«¯åˆ°ç«¯æ— éœ€æ‰‹å·¥è®¾è®¡â€çš„ä¼˜åŠ¿ï¼ŒåŒæ—¶è§£å†³äº†å…¶è®­ç»ƒæ”¶æ•›æ…¢å’Œå°ç›®æ ‡æ£€æµ‹æ€§èƒ½å·®çš„é—®é¢˜ã€‚**

![Screenshot from 2025-05-15 19-06-43](https://github.com/user-attachments/assets/e37860d6-1978-4083-9b55-6b386f8dc47c)

**è®ºæ–‡æ ¸å¿ƒæ˜¯å¼•å…¥äº†Deformable Attentionï¼ˆå¯å˜å½¢æ³¨æ„åŠ›æ¨¡å—ï¼‰ï¼š**

* è¯¥æ¨¡å—åªå…³æ³¨å°‘é‡çš„é‡‡æ ·ç‚¹ï¼ˆå¦‚æ¯ä¸ªæŸ¥è¯¢4ä¸ªç‚¹ï¼‰ï¼Œè€Œä¸æ˜¯æ•´ä¸ªç‰¹å¾å›¾ï¼›

* é‡‡æ ·ç‚¹çš„åç§»ï¼ˆoffsetsï¼‰å’Œæ³¨æ„åŠ›æƒé‡ï¼ˆattention weightsï¼‰éƒ½ç”±æŸ¥è¯¢ç‰¹å¾ç”Ÿæˆï¼›

* æ”¯æŒå¤šå°ºåº¦ç‰¹å¾è¾“å…¥ï¼Œæ›¿ä»£ä¼ ç»Ÿçš„FPNç»“æ„å®ç°å°ºåº¦èåˆï¼›

* æ³¨æ„åŠ›è®¡ç®—å¤æ‚åº¦ç”± $O(H^2W^2)$ é™ä¸ºçº¿æ€§ $O(HW)$ã€‚

**eg**

ç‰¹å¾å›¾å°ºå¯¸ï¼š[C, H, W] = [512, 32, 32]

| é¡¹ç›®             | æ ‡å‡† Transformer                 | Deformable Attention                          |
|------------------|----------------------------------|-----------------------------------------------|
| è¾“å…¥ç‰¹å¾         | `[1024, 512]`                    | åŒå·¦                                          |
| Q ç»´åº¦           | `[1024, 8, 64]`                  | åŒå·¦ï¼ˆç”± FC å¾—åˆ°ï¼‰                            |
| K / V ç»´åº¦       | `[1024, 8, 64]`                  | `[1024, 8, 4, 64]`ï¼ˆä» 4 ä¸ªé‡‡æ ·ç‚¹ä¸­å¾—ï¼‰       |
| é‡‡æ ·æœºåˆ¶         | å…¨éƒ¨åƒç´ åšæ³¨æ„åŠ›ï¼ˆå¯†é›†ï¼‰         | æ¯ä¸ª Query åªé‡‡æ ·å°‘æ•°ç‚¹ï¼ˆå¦‚ 4 ä¸ªï¼‰            |
| è®¡ç®—å¤æ‚åº¦       | `O(N^2) = 10^6`                  | `O(N Ã— 32)`ï¼ˆæ˜¾è‘—é™ä½ï¼Œè¿‘ä¼¼çº¿æ€§ï¼‰             |

###  encoder

**æµç¨‹**

```
z_q âˆˆ [512]
   â”‚
   â”œâ”€â†’ Linear(512â†’2) â†’ å‚è€ƒç‚¹ p_q âˆˆ [2]
   â””â”€â†’ Linear(512â†’96) â†’ reshape â†’
         â”œâ”€ Î”p âˆˆ [8, 4, 2]
         â””â”€ A âˆˆ [8, 4]  â† âœ… å°±æ˜¯ attention æƒé‡

é‡‡æ ·ç‚¹ä½ç½® = p_q + Î”p âˆˆ [8, 4, 2]
   â†“
åŒçº¿æ€§æ’å€¼ç‰¹å¾å›¾ x âˆˆ [256, H, W] â†’ [8, 4, 256]
   â†“
æ¯ä¸ª head ç”¨è‡ªå·±çš„ Linear æ˜ å°„ Value â†’ [8, 4, 64]
   â†“
ä½¿ç”¨ A âˆˆ [8, 4] å¯¹ V åŠ æƒæ±‚å’Œ â†’ [8, 64]
   â†“
æ‹¼æ¥ â†’ å¾—åˆ°è¾“å‡º âˆˆ [512]

```

**query å‘é‡** z_q âˆˆ [512]
```
z_q = torch.linspace(0.0, 1.0, steps=512)
```

**å¾—åˆ°å‚è€ƒç‚¹** p_q âˆˆ [2]
```
nn.Linear(512, 2) + sigmoid
```

å¾—åˆ°ä¸€ä¸ªå‚è€ƒæ¯”ä¾‹ï¼š **x_q** = (0.4, 0.5)


**å¾—åˆ°åç§»ç‚¹** Î”p âˆˆ [8, 4, 2]

ä½¿ç”¨å¦ä¸€ä¸ªå¤§çš„ FC å±‚ï¼ˆå¦‚ nn.Linear(512, 3Ã—MÃ—KÃ—L)ï¼‰æ¥é¢„æµ‹ï¼š M = 8ï¼ˆhead æ•°ï¼‰K = 4ï¼ˆä¸€ä¸ªheadåç§»Kï¼ˆ4ï¼‰æ¬¡ï¼Œå¾—åˆ°4ä¸ªï¼‰ L = 1ï¼ˆç‰¹å¾å›¾å±‚æ•°ï¼ŒEncoder ä¸­ä¸€èˆ¬è®¾ä¸º 1ï¼‰

åç§» Î”pï¼ˆoffsetsï¼‰ï¼š[8, K, L, 2]

æƒé‡ Aï¼ˆattention weightsï¼‰ï¼š[8, K, L]

```
a = torch.tensor([
    a11, a12,  # Î”pâ‚   ,   a13, a14,  # Î”pâ‚‚
    a21, a22,  # Î”pâ‚ƒ   ,   a23, a24,  # Î”pâ‚„
    a31, a32, a33, a34  # Aâ‚~Aâ‚„
])
```


```
p sampled = x_p +Î”p m      ,k âˆˆ[8,4,2]
```

**å¾—åˆ°åƒç´ åæ ‡** [8,4,2]

p sampled å†ä¹˜ä»¥ç‰¹å¾å›¾å¤§å°ï¼ˆå¦‚ 32 Ã— 32ï¼‰å¾—åˆ°åƒç´ åæ ‡ï¼š

```
img_coords = p_sampled * torch.tensor([W, H])  # shape: [8, 4, 2]
```

**Q**
```
features âˆˆ [8, 4, 256]   â† æ¯ä¸ª head çš„æ¯ä¸ªç‚¹ä¸€ä¸ª 256 ç»´å‘é‡
```


**æ˜ å°„å¾—åˆ° Key å’Œ Value** [8, 4, 64]

æ¯ä¸ª head ç”¨è‡ªå·±çš„ W_v âˆˆ [64Ã—256] æ˜ å°„

```
K âˆˆ [8, 4, 64]   â† æ¯ä¸ª headï¼Œ4 ä¸ªé‡‡æ ·ç‚¹ï¼Œæ¯ç‚¹ Key å‘é‡
V âˆˆ [8, 4, 64]   â† Value åŒç†
```

**åŠ æƒæ±‚å’Œ**

 A âˆˆ [8, 4]  * V  âˆˆ [8, 4, 64] = [8,64]

```
weighted_V = [
    0.2408 Ã— [1.0, 2.0, 3.0, 4.0...]    = [0.2408, 0.4816, 0.7224, 0.9632...]
    0.2663 Ã— [5.0, 6.0, 7.0, 8.0...]    = [1.3315, 1.5978, 1.8641, 2.1304...]
    0.2170 Ã— [9.0, 10.0, 11.0, 12.0...] = [1.9530, 2.1700, 2.3870, 2.6040...]
    0.2759 Ã— [13.0, 14.0, 15.0, 16.0...]= [3.5867, 3.8626, 4.1385, 4.4144...]
]


åˆ—æ±‚å’Œï¼š
output = [
    0.2408 + 1.3315 + 1.9530 + 3.5867... = 7.1119,
    0.4816 + 1.5978 + 2.1700 + 3.8626... = 8.1120,
    0.7224 + 1.8641 + 2.3870 + 4.1385... = 9.1120,
    0.9632 + 2.1304 + 2.6040 + 4.4144... = 10.1120
]
```


**æ‹¼æ¥æ‰€æœ‰ head** 

è¾“å‡º [512] 



**ä¾‹å­**

```
Î”p:
tensor([[0.1000, 0.2000],
        [0.3000, 0.4000],
        [0.5000, 0.6000],
        [0.7000, 0.8000]])

A:
tensor([0.2408, 0.2663, 0.2170, 0.2759])  # softmax å
```

```
# å‡è®¾ V ç‰¹å¾ç»´åº¦ä¸º 256
V = torch.tensor([
    [1.0, 2.0, 3.0, 4.0...],
    [5.0, 6.0, 7.0, 8.0...],
    [9.0, 10.0, 11.0, 12.0..],
    [13.0, 14.0, 15.0, 16.0...]
])  # shape: [4, 256]

weighted_V = [
    0.2408 Ã— [1.0, 2.0, 3.0, 4.0...]    = [0.2408, 0.4816, 0.7224, 0.9632...]
    0.2663 Ã— [5.0, 6.0, 7.0, 8.0...]    = [1.3315, 1.5978, 1.8641, 2.1304...]
    0.2170 Ã— [9.0, 10.0, 11.0, 12.0...] = [1.9530, 2.1700, 2.3870, 2.6040...]
    0.2759 Ã— [13.0, 14.0, 15.0, 16.0...]= [3.5867, 3.8626, 4.1385, 4.4144...]
]


åˆ—æ±‚å’Œï¼š
output = [
    0.2408 + 1.3315 + 1.9530 + 3.5867... = 7.1119+...,
    0.4816 + 1.5978 + 2.1700 + 3.8626... = 8.1120+...,
    0.7224 + 1.8641 + 2.3870 + 4.1385... = 9.1120+...,
    0.9632 + 2.1304 + 2.6040 + 4.4144... = 10.1120+...
]

output = tensor([7.1119, 8.1120, 9.1120, 10.1120...])  # shape: [256]
```



### decoder

**æ¦‚è¿°ï¼š**

åœ¨decoderä¸­ï¼Œobject query(å¯æ›´æ–°çš„tensor)åšself-attentionï¼Œç„¶åè¾“å‡º1.xy,2,delta_x,delta_y,Aï¼Œåœ¨encoderè¾“å‡ºä¸­æ‰¾åˆ°V:M*Hä¸ª[256] ï¼Œç„¶åA*Vï¼Œflattenè¾“å‡º[256]

### ğŸš©Step 1ï¼šObject Queryï¼ˆå¯æ›´æ–°çš„ Tensorï¼‰

- æ˜¯ä¸€ä¸ª learnable Tensorï¼Œæ¯”å¦‚ shapeï¼š

  ```
  object_queries âˆˆ [num_queries=300, 256]
  ```

- Decoder å±‚ä¼šå¤šæ¬¡æ›´æ–°å®ƒã€‚

* N = num_queries = 300ï¼šæ¯ä¸ª query è¡¨ç¤ºâ€œæˆ‘è¦æ‰¾ä¸€ä¸ªç›®æ ‡â€.



### ğŸš©Step 2ï¼šé¢„æµ‹å‚è€ƒç‚¹ + é‡‡æ ·åç§» + æ³¨æ„åŠ›æƒé‡

å¯¹æ¯ä¸ª `z_q âˆˆ [256]`ï¼š

- ç»è¿‡ Linear è¾“å‡ºï¼š

| åç§°             | ç»´åº¦           | è¯´æ˜                               |
| ---------------- | -------------- | ---------------------------------- |
| **å‚è€ƒç‚¹** `p_q` | `[2]`          | å½’ä¸€åŒ–åæ ‡ï¼Œè¡¨ç¤ºé‡‡æ ·ä¸­å¿ƒ           |
| **Î”p**           | `[M, K, L, 2]` | åç§»å‘é‡ï¼ŒMä¸ªheadï¼ŒKä¸ªç‚¹ï¼ŒLä¸ªå°ºåº¦  |
| **A**            | `[M, K, L]`    | æ³¨æ„åŠ›æƒé‡ï¼Œå¯¹æ¯ä¸ªé‡‡æ ·ç‚¹åš softmax |

### ğŸš©Step 3ï¼šå¯¹æ¯ä¸ª head çš„é‡‡æ ·ç‚¹åš Linear æ˜ å°„ â†’ `[M, K, L, 64]`

- ä½¿ç”¨ `W_v^m` æ˜ å°„æ¯ä¸ªç‚¹çš„ `[256] â†’ 64`ï¼Œå¾—åˆ°ï¼š

  ```
  V âˆˆ [M=8, K=4, L=4, 64]
  ```





**Self-Attention çš„ç»“æ„**

```
Z âˆˆ [300, 256]
â†“
Q = Z @ W_q â†’ [300, 8, 32]
K = Z @ W_k â†’ [300, 8, 32]
V = Z @ W_v â†’ [300, 8, 32]
â†“
Attention(Q, K, V) = softmax(QÂ·K^T) @ V â†’ [300, 8, 32]
â†“
Concat 8 heads â†’ [300, 256]
â†“
Residual + LayerNorm â†’ [300, 256]
```

**Cross-Attention ä¸­çš„æ ¸å¿ƒæµç¨‹å¦‚ä¸‹ï¼ˆå¯¹æ¯ä¸ª object queryï¼‰ï¼š**

```
z_q âˆˆ [256]
â†“
Linear â†’ å‚è€ƒç‚¹ p_q âˆˆ [2]
â†“
Linear â†’ Î”p âˆˆ [8, 4, 4, 2],  A âˆˆ [8, 4, 4]
â†“
p_sample = p_q + Î”p  âˆˆ [8, 4, 4, 2]
â†“
åœ¨ encoder è¾“å‡ºçš„å¤šå°ºåº¦ç‰¹å¾å›¾ä¸Šæ’å€¼é‡‡æ · â†’ V âˆˆ [8, 4, 4, 256]
â†“
Linearï¼ˆper-headï¼‰â†’ [8, 4, 4, 64]
â†“
A Ã— V â†’ [8, 64]
â†“
Concat â†’ [512] â†’ Linear â†’ [256]
â†“
åŠ ä¸Šæ®‹å·® z_q â†’ ä¸‹ä¸€å±‚
```
